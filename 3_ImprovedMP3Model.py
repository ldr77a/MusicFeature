import os
import numpy as np
import pandas as pd
import librosa
import librosa.display
import joblib
import warnings
from scipy.stats import skew, kurtosis
from tqdm import tqdm
import argparse

# Librosa ê²½ê³  ë©”ì‹œì§€ í•„í„°ë§
warnings.filterwarnings("ignore", message="n_fft=.*is too large for input signal of length.*")

def extract_features(y, sr, start_time, end_time):
    """
    ì£¼ì–´ì§„ ì˜¤ë””ì˜¤ ì„¸ê·¸ë¨¼íŠ¸ì—ì„œ ìŒì•… íŠ¹ì§•ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    
    Parameters:
    y (np.ndarray): ì˜¤ë””ì˜¤ ì‹œê³„ì—´
    sr (int): ìƒ˜í”Œë§ ë ˆì´íŠ¸
    start_time (float): ì‹œì‘ ì‹œê°„ (ì´ˆ)
    end_time (float): ì¢…ë£Œ ì‹œê°„ (ì´ˆ)
    
    Returns:
    dict: ì¶”ì¶œëœ íŠ¹ì§•ë“¤ì„ í¬í•¨í•˜ëŠ” ì‚¬ì „
    """
    # ì‹œê°„ ì¸ë±ìŠ¤ë¥¼ ìƒ˜í”Œ ì¸ë±ìŠ¤ë¡œ ë³€í™˜
    start_idx = int(start_time * sr)
    end_idx = int(end_time * sr)
    
    # ì„¸ê·¸ë¨¼íŠ¸ ì¶”ì¶œ
    y_segment = y[start_idx:end_idx]
    
    # ì‹ í˜¸ì˜ ê¸¸ì´ì— ë§ê²Œ ì ì ˆí•œ n_fft ê°’ ì„¤ì •
    signal_length = len(y_segment)
    
    # n_fftë¥¼ ì‹ í˜¸ ê¸¸ì´ë³´ë‹¤ ì‘ê²Œ ì„¤ì • (2ì˜ ê±°ë“­ì œê³± ê°’ìœ¼ë¡œ)
    if signal_length < 1024:
        # ì‹ í˜¸ ê¸¸ì´ë³´ë‹¤ ì‘ì€ 2ì˜ ê±°ë“­ì œê³± ê°’ ì°¾ê¸°
        n_fft = 2 ** int(np.log2(signal_length))
        # ìµœì†Œ n_fft ê°’ì´ 32ë³´ë‹¤ ì‘ìœ¼ë©´ 32ë¡œ ì„¤ì •
        n_fft = max(32, n_fft)
        hop_length = n_fft // 4
    else:
        n_fft = 1024
        hop_length = 256
    
    # íŠ¹ì§•ë“¤ì„ ì €ì¥í•  ë”•ì…”ë„ˆë¦¬
    features = {}
    
    # 1. ë‹¤ì–‘í•œ Chroma íŠ¹ì§•ë“¤
    
    # 1.1 Chroma Energy Normalized (CENS)
    chroma_cens = librosa.feature.chroma_cens(y=y_segment, sr=sr, hop_length=hop_length)
    
    # 1.2 ê¸°ë³¸ Chroma feature
    chroma_stft = librosa.feature.chroma_stft(y=y_segment, sr=sr, n_fft=n_fft, hop_length=hop_length)
    
    # 1.3 Constant-Q chroma
    chroma_cqt = librosa.feature.chroma_cqt(y=y_segment, sr=sr, hop_length=hop_length)
    
    # ê° ìŒê³„ë³„ í‰ê· ê°’ê³¼ í‘œì¤€í¸ì°¨ ê³„ì‚° (í†µê³„ì  íŠ¹ì„± í™•ì¥)
    note_names = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B']
    
    for i, note in enumerate(note_names):
        # CENS
        features[f'{note}_CENS_mean'] = np.mean(chroma_cens[i])
        features[f'{note}_CENS_std'] = np.std(chroma_cens[i])
        
        # STFT
        features[f'{note}_STFT_mean'] = np.mean(chroma_stft[i])
        features[f'{note}_STFT_std'] = np.std(chroma_stft[i])
        
        # CQT
        features[f'{note}_CQT_mean'] = np.mean(chroma_cqt[i])
        features[f'{note}_CQT_std'] = np.std(chroma_cqt[i])
    
    # 2. í™•ì¥ëœ MFCC - 20ê°œì˜ ê³„ìˆ˜ + ë¸íƒ€ + ë¸íƒ€ë¸íƒ€
    n_mfcc = 20  # MFCC ê°œìˆ˜ë¥¼ 20ê°œë¡œ í™•ì¥
    mfcc = librosa.feature.mfcc(y=y_segment, sr=sr, n_mfcc=n_mfcc, n_fft=n_fft, hop_length=hop_length)
    mfcc_delta = librosa.feature.delta(mfcc)  # ë¸íƒ€ MFCC
    mfcc_delta2 = librosa.feature.delta(mfcc, order=2)  # ë¸íƒ€ë¸íƒ€ MFCC
    
    # ê° MFCC ê³„ìˆ˜ë³„ í‰ê· , í‘œì¤€í¸ì°¨, ì²¨ë„, ì™œë„ ê³„ì‚°
    for i in range(n_mfcc):
        # ê¸°ë³¸ MFCC
        features[f'MFCC_{i}_mean'] = np.mean(mfcc[i])
        features[f'MFCC_{i}_std'] = np.std(mfcc[i])
        
        # ì²¨ë„ì™€ ì™œë„ëŠ” í†µê³„ì ìœ¼ë¡œ ìœ ìš©í•œ íŠ¹ì„±ì´ì§€ë§Œ, ì²« 10ê°œ ê³„ìˆ˜ì—ë§Œ ì ìš©í•˜ì—¬ íŠ¹ì§• ìˆ˜ ì œí•œ
        if i < 10:
            features[f'MFCC_{i}_kurtosis'] = kurtosis(mfcc[i], fisher=True, nan_policy='omit')
            features[f'MFCC_{i}_skewness'] = skew(mfcc[i], nan_policy='omit')
        
        # ë¸íƒ€ MFCC (ë³€í™”ìœ¨)
        features[f'MFCC_delta_{i}_mean'] = np.mean(mfcc_delta[i])
        features[f'MFCC_delta_{i}_std'] = np.std(mfcc_delta[i])
        
        # ë¸íƒ€-ë¸íƒ€ MFCC (ê°€ì†ë„) - ì²« 10ê°œë§Œ ì‚¬ìš©í•˜ì—¬ íŠ¹ì§• ìˆ˜ ì œí•œ
        if i < 10:
            features[f'MFCC_delta2_{i}_mean'] = np.mean(mfcc_delta2[i])
            features[f'MFCC_delta2_{i}_std'] = np.std(mfcc_delta2[i])
    
    # 3. Tonnetz - ì¡°ì„± ì„¼íŠ¸ë¡œì´ë“œì™€ ê´€ë ¨ëœ íŠ¹ì§•
    y_harmonic = librosa.effects.harmonic(y_segment)  # í•˜ëª¨ë‹‰ ì„±ë¶„ ì¶”ì¶œ
    tonnetz = librosa.feature.tonnetz(y=y_harmonic, sr=sr)
    
    # ê° í†¤ë„¤ì¸  ì°¨ì›ì˜ íŠ¹ì„± ì¶”ì¶œ (6ê°œ ì°¨ì›)
    tonnetz_names = ['tonnetz_0', 'tonnetz_1', 'tonnetz_2', 'tonnetz_3', 'tonnetz_4', 'tonnetz_5']
    for i, name in enumerate(tonnetz_names):
        features[f'{name}_mean'] = np.mean(tonnetz[i])
        features[f'{name}_std'] = np.std(tonnetz[i])
    
    # 4. ìŠ¤í™íŠ¸ëŸ¼ íŠ¹ì„±ë“¤
    
    # 4.1 Spectral Centroid (í‰ê· ê³¼ í‘œì¤€í¸ì°¨)
    spectral_centroid = librosa.feature.spectral_centroid(y=y_segment, sr=sr, n_fft=n_fft, hop_length=hop_length)
    features['spectral_centroid_mean'] = np.mean(spectral_centroid)
    features['spectral_centroid_std'] = np.std(spectral_centroid)
    
    # 4.2 Spectral Bandwidth
    spectral_bandwidth = librosa.feature.spectral_bandwidth(y=y_segment, sr=sr, n_fft=n_fft, hop_length=hop_length)
    features['spectral_bandwidth_mean'] = np.mean(spectral_bandwidth)
    features['spectral_bandwidth_std'] = np.std(spectral_bandwidth)
    
    # 4.3 Spectral Contrast (7ê°œ ëŒ€ì—­)
    spectral_contrast = librosa.feature.spectral_contrast(y=y_segment, sr=sr, n_fft=n_fft, hop_length=hop_length)
    
    for i in range(7):
        features[f'contrast_{i}_mean'] = np.mean(spectral_contrast[i])
        features[f'contrast_{i}_std'] = np.std(spectral_contrast[i])
    
    # 4.4 Spectral Flatness
    spectral_flatness = librosa.feature.spectral_flatness(y=y_segment, n_fft=n_fft, hop_length=hop_length)
    features['spectral_flatness_mean'] = np.mean(spectral_flatness)
    features['spectral_flatness_std'] = np.std(spectral_flatness)
    
    # 4.5 Spectral Rolloff
    spectral_rolloff = librosa.feature.spectral_rolloff(y=y_segment, sr=sr, n_fft=n_fft, hop_length=hop_length)
    features['spectral_rolloff_mean'] = np.mean(spectral_rolloff)
    features['spectral_rolloff_std'] = np.std(spectral_rolloff)
    
    # 4.6 Zero Crossing Rate
    zero_crossing_rate = librosa.feature.zero_crossing_rate(y=y_segment, hop_length=hop_length)
    features['zero_crossing_rate_mean'] = np.mean(zero_crossing_rate)
    features['zero_crossing_rate_std'] = np.std(zero_crossing_rate)
    
    # 5. ë¦¬ë“¬ íŠ¹ì„±ë“¤
    
    # 5.1 Tempo
    tempo, _ = librosa.beat.beat_track(y=y_segment, sr=sr, hop_length=hop_length)
    # NumPy ë°°ì—´ì„ ìŠ¤ì¹¼ë¼ë¡œ ë³€í™˜í•  ë•Œ ê²½ê³ ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•œ ì˜¬ë°”ë¥¸ ë°©ë²•
    if hasattr(tempo, 'item'):
        tempo = tempo.item()  # NumPy ë°°ì—´ì—ì„œ ë‹¨ì¼ ê°’ ì¶”ì¶œ
    else:
        tempo = float(tempo)  # ë‹¤ë¥¸ íƒ€ì…ì˜ ê²½ìš° ë‹¨ìˆœ ë³€í™˜
    features['tempo'] = tempo
    
    # 5.2 ë¦¬ë“¬ íŠ¹ì„±: ì‹œê°„ì¶• Autocorrelation - ë¦¬ë“¬ ê·œì¹™ì„± ì¸¡ì •
    # ë¦¬ë“¬ì˜ ìê¸°ìƒê´€ í•¨ìˆ˜ëŠ” ë°˜ë³µì ì¸ ë¦¬ë“¬ íŒ¨í„´ì„ ì°¾ëŠ”ë° ìœ ìš©í•©ë‹ˆë‹¤
    y_perc = librosa.effects.percussive(y_segment)  # íƒ€ì•…ê¸°(í¼ì»¤ì‹œë¸Œ) ì„±ë¶„ ì¶”ì¶œ
    onset_env = librosa.onset.onset_strength(y=y_perc, sr=sr, hop_length=hop_length)
    ac = librosa.autocorrelate(onset_env, max_size=sr // hop_length // 2)
    ac = librosa.util.normalize(ac, norm=np.inf)
    
    # ìê¸°ìƒê´€ í•¨ìˆ˜ì—ì„œ í”¼í¬ ì¶”ì¶œ (ë¦¬ë“¬ ì£¼ê¸°ì„± ì¸¡ì •)
    peaks = librosa.util.peak_pick(ac, pre_max=10, post_max=10, pre_avg=10, post_avg=10, delta=0.5, wait=10)
    
    if len(peaks) > 0:
        features['rhythm_periodicity'] = len(peaks)  # í”¼í¬ ìˆ˜ (ë¦¬ë“¬ ë³µì¡ì„± ì§€í‘œ)
        features['rhythm_strength'] = np.mean(ac[peaks])  # í”¼í¬ ê°•ë„ í‰ê·  (ë¦¬ë“¬ ê°•ì¡° ì •ë„)
    else:
        features['rhythm_periodicity'] = 0
        features['rhythm_strength'] = 0
    
    # 5.3 ë¦¬ë“¬ ê°•ë„ í†µê³„
    features['onset_strength_mean'] = np.mean(onset_env)
    features['onset_strength_std'] = np.std(onset_env)
    
    # 6. Band Energy Ratio
    # ì£¼íŒŒìˆ˜ ëŒ€ì—­ë³„ ì—ë„ˆì§€ ë¶„í¬ - ì €ì£¼íŒŒ/ì¤‘ê°„ì£¼íŒŒ/ê³ ì£¼íŒŒ ì—ë„ˆì§€ì˜ ìƒëŒ€ì  ë¹„ìœ¨
    # ì˜¤ë””ì˜¤ ì‹ í˜¸ì˜ ì—ë„ˆì§€ê°€ ì–´ë–¤ ì£¼íŒŒìˆ˜ ëŒ€ì—­ì— ì§‘ì¤‘ë˜ì–´ ìˆëŠ”ì§€ íŒŒì•…
    D = np.abs(librosa.stft(y_segment, n_fft=n_fft, hop_length=hop_length))
    
    # ì£¼íŒŒìˆ˜ ë¹ˆì„ 3ê°œ ëŒ€ì—­ìœ¼ë¡œ ë‚˜ëˆ„ê¸°
    n_bands = 3
    band_size = D.shape[0] // n_bands
    
    # ê° ì£¼íŒŒìˆ˜ ëŒ€ì—­ì˜ ì—ë„ˆì§€ ê³„ì‚°
    band_energy = []
    for i in range(n_bands):
        start_bin = i * band_size
        end_bin = min((i + 1) * band_size, D.shape[0])
        band_energy.append(np.sum(D[start_bin:end_bin, :] ** 2))
    
    # ì „ì²´ ì—ë„ˆì§€ë¡œ ì •ê·œí™”í•˜ì—¬ ë¹„ìœ¨ ê³„ì‚°
    total_energy = np.sum(band_energy)
    if total_energy > 0:
        for i in range(n_bands):
            features[f'band_energy_ratio_{i}'] = band_energy[i] / total_energy
    else:
        for i in range(n_bands):
            features[f'band_energy_ratio_{i}'] = 0
    
    # 7. RMS ì—ë„ˆì§€ - ìŒëŸ‰ê³¼ ê´€ë ¨
    rms = librosa.feature.rms(y=y_segment, hop_length=hop_length)
    features['rms_mean'] = np.mean(rms)
    features['rms_std'] = np.std(rms)
    
    # 8. í•˜ëª¨ë‹‰/í¼ì»¤ì‹œë¸Œ ì„±ë¶„ ë¹„ìœ¨
    y_harmonic = librosa.effects.harmonic(y_segment)
    y_percussive = librosa.effects.percussive(y_segment)
    
    # í•˜ëª¨ë‹‰ ì—ë„ˆì§€ì™€ í¼ì»¤ì‹œë¸Œ ì—ë„ˆì§€ ê³„ì‚°
    harmonic_energy = np.sum(y_harmonic ** 2)
    percussive_energy = np.sum(y_percussive ** 2)
    total_energy = harmonic_energy + percussive_energy
    
    if total_energy > 0:
        features['harmonic_ratio'] = harmonic_energy / total_energy
        features['percussive_ratio'] = percussive_energy / total_energy
    else:
        features['harmonic_ratio'] = 0
        features['percussive_ratio'] = 0
    
    # ì‹œì‘ ë° ì¢…ë£Œ ì‹œê°„ ì¶”ê°€
    features['start_time'] = start_time
    features['end_time'] = end_time
    
    # NaN ê°’ì„ 0ìœ¼ë¡œ ëŒ€ì²´
    for key in features:
        if np.isnan(features[key]):
            features[key] = 0
    
    return features

def load_trained_model_and_scaler(model_dir="Model"):
    """
    í•™ìŠµëœ SMOTE ëª¨ë¸ê³¼ ìŠ¤ì¼€ì¼ëŸ¬ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
    
    Args:
        model_dir (str): ëª¨ë¸ì´ ì €ì¥ëœ ë””ë ‰í† ë¦¬
        
    Returns:
        tuple: (ëª¨ë¸, ìŠ¤ì¼€ì¼ëŸ¬, ì‚¬ìš©ëœ íŠ¹ì§• ëª©ë¡, ê°ì • ë ˆì´ë¸” ë§¤í•‘)
    """
    print(f"'{model_dir}' í´ë”ì—ì„œ í•™ìŠµëœ ëª¨ë¸ì„ ë¡œë“œ ì¤‘...")
    
    # ëª¨ë¸ íŒŒì¼ ê²½ë¡œ (ìƒˆë¡œìš´ ëª¨ë¸ ìš°ì„  ì‹œë„)
    model_path = os.path.join(model_dir, 'smote_model2.pkl')
    scaler_path = os.path.join(model_dir, 'smote_scaler2.pkl')
    
    # ìƒˆ ëª¨ë¸ì´ ì—†ìœ¼ë©´ ê¸°ì¡´ ëª¨ë¸ ì‚¬ìš©
    if not os.path.exists(model_path):
        model_path = os.path.join(model_dir, 'smote_model2.pkl')
        scaler_path = os.path.join(model_dir, 'smote_scaler2.pkl')
    
    features_path = os.path.join(model_dir, 'smote_features.txt')
    
    # íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    if not os.path.exists(model_path):
        raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {model_path}")
    if not os.path.exists(scaler_path):
        raise FileNotFoundError(f"ìŠ¤ì¼€ì¼ëŸ¬ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {scaler_path}")
    if not os.path.exists(features_path):
        raise FileNotFoundError(f"íŠ¹ì§• ëª©ë¡ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {features_path}")
    
    # ëª¨ë¸ê³¼ ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
    model = joblib.load(model_path)
    scaler = joblib.load(scaler_path)
    
    # ì‚¬ìš©ëœ íŠ¹ì§• ëª©ë¡ ë¡œë“œ
    with open(features_path, 'r') as f:
        feature_names = [line.strip() for line in f.readlines()]
    
    # ê°ì • ë ˆì´ë¸” ë§¤í•‘ (emotion_id -> emotion_name)
    emotion_mapping = {
        1: 'Sad',
        2: 'Annoying', 
        3: 'Calme',
        4: 'Amusing'
    }
    
    print(f"ëª¨ë¸ ë¡œë“œ ì™„ë£Œ. ì‚¬ìš©í•  íŠ¹ì§• ìˆ˜: {len(feature_names)}")
    print("ê°ì • ë ˆì´ë¸” ë§¤í•‘:")
    for emotion_id, emotion_name in emotion_mapping.items():
        print(f"  {emotion_id}: {emotion_name}")
    
    return model, scaler, feature_names, emotion_mapping

def apply_emotion_threshold(probabilities, thresholds):
    """
    ê°ì •ë³„ í™•ë¥  ì„ê³„ê°’ì„ ì ìš©í•˜ì—¬ ë” ê· í˜•ì¡íŒ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    
    Args:
        probabilities (np.array): 4ê°œ ê°ì •ì˜ í™•ë¥  [Sad, Annoying, Calme, Amusing]
        thresholds (dict): ê°ì •ë³„ ì„ê³„ê°’ {emotion_id: threshold}
        
    Returns:
        tuple: (adjusted_emotion_id, confidence, original_emotion_id)
    """
    # ì›ë³¸ ì˜ˆì¸¡
    original_emotion_id = np.argmax(probabilities) + 1
    
    # ì„ê³„ê°’ ì ìš©
    adjusted_probs = probabilities.copy()
    
    # Amusing(4)ì˜ ì„ê³„ê°’ì„ ë†’ì—¬ì„œ ê³¼ë„í•œ ë¶„ë¥˜ ë°©ì§€
    if 4 in thresholds:
        if probabilities[3] < thresholds[4]:  # Amusingì´ ì„ê³„ê°’ë³´ë‹¤ ë‚®ìœ¼ë©´
            adjusted_probs[3] *= 0.55
    
    # ë‹¤ë¥¸ ê°ì •ë“¤ì˜ ì„ê³„ê°’ ì ìš©
    for emotion_id, threshold in thresholds.items():
        if emotion_id <= 3:  # Sad(1), Annoying(2), Calme(3)
            if probabilities[emotion_id-1] >= threshold:
                adjusted_probs[emotion_id-1] *= 1.2  # í™•ë¥ ì„ ì¦ê°€
    
    # ì¡°ì •ëœ ì˜ˆì¸¡
    adjusted_emotion_id = np.argmax(adjusted_probs) + 1
    confidence = np.max(adjusted_probs)
    
    return adjusted_emotion_id, confidence, original_emotion_id

def process_mp3_file(file_path, model, scaler, feature_names, emotion_mapping, 
                    segment_duration=5.0, use_threshold=True):
    """
    MP3 íŒŒì¼ì„ ì§€ì •ëœ ê°„ê²©ìœ¼ë¡œ ì²˜ë¦¬í•˜ì—¬ ê°ì • ë¶„ë¥˜ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    
    Args:
        file_path (str): MP3 íŒŒì¼ ê²½ë¡œ
        model: í•™ìŠµëœ ëª¨ë¸
        scaler: í•™ìŠµëœ ìŠ¤ì¼€ì¼ëŸ¬
        feature_names (list): ì‚¬ìš©í•  íŠ¹ì§• ì´ë¦„ ëª©ë¡
        emotion_mapping (dict): ê°ì • ID -> ê°ì • ì´ë¦„ ë§¤í•‘
        segment_duration (float): ì„¸ê·¸ë¨¼íŠ¸ ì§€ì† ì‹œê°„ (ì´ˆ)
        use_threshold (bool): í™•ë¥  ì„ê³„ê°’ ì ìš© ì—¬ë¶€
        
    Returns:
        pd.DataFrame: ê°ì • ë¶„ë¥˜ ê²°ê³¼ë¥¼ í¬í•¨í•˜ëŠ” ë°ì´í„°í”„ë ˆì„
    """
    print(f"MP3 íŒŒì¼ ì²˜ë¦¬ ì¤‘: {file_path}")
    print(f"ì„¸ê·¸ë¨¼íŠ¸ ê¸¸ì´: {segment_duration}ì´ˆ")
    print(f"í™•ë¥  ì„ê³„ê°’ ì ìš©: {'ì˜ˆ' if use_threshold else 'ì•„ë‹ˆì˜¤'}")
    
    # ì˜¤ë””ì˜¤ ë¡œë“œ
    try:
        y, sr = librosa.load(file_path, sr=None)
    except Exception as e:
        raise ValueError(f"ì˜¤ë””ì˜¤ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    # íŒŒì¼ ì§€ì† ì‹œê°„ í™•ì¸
    duration = librosa.get_duration(y=y, sr=sr)
    print(f"íŒŒì¼ ì§€ì† ì‹œê°„: {duration:.2f}ì´ˆ")
    
    # í™•ë¥  ì„ê³„ê°’ ì„¤ì • (Amusing ê³¼ë„ ë¶„ë¥˜ ë°©ì§€)
    emotion_thresholds = {
        1: 0.4,  # Sad
        2: 0.4,  # Annoying  
        3: 0.4,  # Calme
        4: 0.6   # Amusing - ë†’ì€ ì„ê³„ê°’ìœ¼ë¡œ ê³¼ë„í•œ ë¶„ë¥˜ ë°©ì§€
    }
    
    # ê²°ê³¼ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
    results = []
    
    # ì§€ì •ëœ ê°„ê²©ìœ¼ë¡œ ì„¸ê·¸ë¨¼íŠ¸ ìƒì„±
    start_times = np.arange(0, duration, segment_duration)
    print(f"ì´ {len(start_times)}ê°œì˜ ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
    
    # ê° ì„¸ê·¸ë¨¼íŠ¸ì— ëŒ€í•´ ì²˜ë¦¬
    for i, start_time in enumerate(tqdm(start_times, desc="ì„¸ê·¸ë¨¼íŠ¸ ì²˜ë¦¬")):
        end_time = min(start_time + segment_duration, duration)
        
        # íŠ¹ì§• ì¶”ì¶œ
        try:
            features = extract_features(y, sr, start_time, end_time)
        except Exception as e:
            print(f"ê²½ê³ : ì„¸ê·¸ë¨¼íŠ¸ {i+1} íŠ¹ì§• ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            continue
        
        # ëª¨ë¸ì— í•„ìš”í•œ íŠ¹ì§•ë§Œ ì„ íƒ
        selected_features = []
        missing_features = []
        
        for feature_name in feature_names:
            if feature_name in features:
                selected_features.append(features[feature_name])
            else:
                selected_features.append(0)  # ëˆ„ë½ëœ íŠ¹ì§•ì€ 0ìœ¼ë¡œ ëŒ€ì²´
                missing_features.append(feature_name)
        
        if missing_features and i == 0:  # ì²« ë²ˆì§¸ ì„¸ê·¸ë¨¼íŠ¸ì—ì„œë§Œ ê²½ê³  ì¶œë ¥
            print(f"ê²½ê³ : ëˆ„ë½ëœ íŠ¹ì§•ë“¤ (ì²˜ìŒ 5ê°œë§Œ í‘œì‹œ): {missing_features[:5]}...")
        
        # íŠ¹ì§• ë²¡í„°ë¥¼ 2D ë°°ì—´ë¡œ ë³€í™˜ (1ê°œ ìƒ˜í”Œ)
        X = np.array(selected_features).reshape(1, -1)
        
        # ìŠ¤ì¼€ì¼ë§ ì ìš©
        try:
            X_scaled = scaler.transform(X)
        except Exception as e:
            print(f"ê²½ê³ : ì„¸ê·¸ë¨¼íŠ¸ {i+1} ìŠ¤ì¼€ì¼ë§ ì‹¤íŒ¨: {e}")
            continue
        
        # ê°ì • ì˜ˆì¸¡
        try:
            emotion_prob = model.predict_proba(X_scaled)[0]
            
            if use_threshold:
                # ì„ê³„ê°’ ì ìš©
                emotion_id, confidence, original_emotion_id = apply_emotion_threshold(
                    emotion_prob, emotion_thresholds)
                emotion_name = emotion_mapping.get(emotion_id, 'Unknown')
                original_emotion_name = emotion_mapping.get(original_emotion_id, 'Unknown')
            else:
                # ê¸°ë³¸ ì˜ˆì¸¡
                emotion_id = model.predict(X_scaled)[0]
                confidence = np.max(emotion_prob)
                emotion_name = emotion_mapping.get(emotion_id, 'Unknown')
                original_emotion_id = emotion_id
                original_emotion_name = emotion_name
                
        except Exception as e:
            print(f"ê²½ê³ : ì„¸ê·¸ë¨¼íŠ¸ {i+1} ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
            continue
        
        # ê²°ê³¼ ì €ì¥
        result = {
            'segment_id': i + 1,
            'start_time': start_time,
            'end_time': end_time,
            'duration': end_time - start_time,
            'emotion_id': emotion_id,
            'emotion': emotion_name,
            'confidence': confidence,
        }
        
        # model.classes_ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •í™•í•œ í™•ë¥  ë§¤í•‘
        model_classes = model.classes_  # ì˜ˆ: [1, 2, 3, 4]
        for idx, class_label in enumerate(model_classes):
            emotion_name_for_prob = emotion_mapping.get(class_label, f'Unknown_{class_label}')
            result[f'probability_{emotion_name_for_prob}'] = emotion_prob[idx]
        
        # ì„ê³„ê°’ ì ìš©ì‹œ ì›ë³¸ ì˜ˆì¸¡ë„ ì €ì¥
        if use_threshold:
            result['original_emotion_id'] = original_emotion_id
            result['original_emotion'] = original_emotion_name
            
        results.append(result)
    
    # ê²°ê³¼ë¥¼ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜
    df = pd.DataFrame(results)
    
    print(f"ì²˜ë¦¬ ì™„ë£Œ. ì´ {len(df)}ê°œì˜ ì„¸ê·¸ë¨¼íŠ¸ê°€ ë¶„ì„ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    return df

def get_mp3_file_interactive():
    """
    ì‚¬ìš©ìê°€ ëŒ€í™”í˜•ìœ¼ë¡œ MP3 íŒŒì¼ì„ ì„ íƒí•  ìˆ˜ ìˆë„ë¡ í•©ë‹ˆë‹¤.
    
    Returns:
        str: ì„ íƒëœ MP3 íŒŒì¼ ê²½ë¡œ
    """
    print("ğŸµ MP3 íŒŒì¼ ì„ íƒ ğŸµ")
    print("=" * 50)
    
    # TestMusic í´ë” í™•ì¸
    test_music_folder = "TestMusic"
    if os.path.isdir(test_music_folder):
        mp3_files = [f for f in os.listdir(test_music_folder) if f.lower().endswith('.mp3')]
        
        if mp3_files:
            print(f"\nğŸ“ '{test_music_folder}' í´ë”ì˜ MP3 íŒŒì¼ ëª©ë¡:")
            for i, file in enumerate(mp3_files, 1):
                print(f"  {i}. {file}")
            
            print(f"\nì„ íƒ ì˜µì…˜:")
            print(f"  1-{len(mp3_files)}: ìœ„ ëª©ë¡ì—ì„œ ë²ˆí˜¸ ì„ íƒ")
            print(f"  0: ì§ì ‘ íŒŒì¼ ê²½ë¡œ ì…ë ¥")
            
            while True:
                try:
                    choice = input(f"\nì„ íƒí•˜ì„¸ìš” (0-{len(mp3_files)}): ").strip()
                    
                    if choice == '0':
                        # ì§ì ‘ íŒŒì¼ ê²½ë¡œ ì…ë ¥
                        file_path = input("MP3 íŒŒì¼ì˜ ì „ì²´ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
                        if os.path.exists(file_path) and file_path.lower().endswith('.mp3'):
                            return file_path
                        else:
                            print("âŒ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•Šê±°ë‚˜ MP3 íŒŒì¼ì´ ì•„ë‹™ë‹ˆë‹¤. ë‹¤ì‹œ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                            continue
                    
                    choice_num = int(choice)
                    if 1 <= choice_num <= len(mp3_files):
                        selected_file = os.path.join(test_music_folder, mp3_files[choice_num - 1])
                        return selected_file
                    else:
                        print(f"âŒ 1-{len(mp3_files)} ë˜ëŠ” 0ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                
                except ValueError:
                    print("âŒ ìˆ«ìë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            print(f"\nğŸ“ '{test_music_folder}' í´ë”ì— MP3 íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    else:
        print(f"\nğŸ“ '{test_music_folder}' í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    # TestMusic í´ë”ì— íŒŒì¼ì´ ì—†ê±°ë‚˜ í´ë”ê°€ ì—†ëŠ” ê²½ìš°
    print("\nì§ì ‘ MP3 íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    while True:
        file_path = input("MP3 íŒŒì¼ì˜ ì „ì²´ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
        if file_path == '':
            print("âŒ íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            continue
        
        if os.path.exists(file_path) and file_path.lower().endswith('.mp3'):
            return file_path
        else:
            print("âŒ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•Šê±°ë‚˜ MP3 íŒŒì¼ì´ ì•„ë‹™ë‹ˆë‹¤. ë‹¤ì‹œ ì…ë ¥í•´ì£¼ì„¸ìš”.")



def smooth_predictions(df, emotion_mapping, window_size=3):
    """
    ì´ë™ í‰ê·  í•„í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ê°ì • ì˜ˆì¸¡ì„ í‰í™œí™”í•©ë‹ˆë‹¤.
    
    Args:
        df (pd.DataFrame): ì›ë³¸ ì˜ˆì¸¡ ê²°ê³¼ ë°ì´í„°í”„ë ˆì„
        emotion_mapping (dict): ê°ì • ID -> ê°ì • ì´ë¦„ ë§¤í•‘
        window_size (int): í‰ê· ì„ ê³„ì‚°í•  ì°½ í¬ê¸° (í™€ìˆ˜ ê¶Œì¥)
        
    Returns:
        pd.DataFrame: í‰í™œí™”ëœ ì˜ˆì¸¡ ê²°ê³¼ê°€ ì¶”ê°€ëœ ë°ì´í„°í”„ë ˆì„
    """
    print(f"\nê²°ê³¼ í‰í™œí™” ì¤‘... (ì°½ í¬ê¸°: {window_size})")
    
    # í™•ë¥  ì»¬ëŸ¼ ëª©ë¡ ìƒì„±
    prob_cols = [col for col in df.columns if col.startswith('probability_')]
    
    if not prob_cols:
        print("ê²½ê³ : í™•ë¥  ì»¬ëŸ¼ì´ ì—†ì–´ í‰í™œí™”ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
        return df
    
    # í™•ë¥  ê°’ì— ì´ë™ í‰ê·  ì ìš©
    # center=TrueëŠ” í˜„ì¬ í¬ì¸íŠ¸ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì°½ì„ ì„¤ì •
    smoothed_probs = df[prob_cols].rolling(window=window_size, center=True, min_periods=1).mean()
    
    # í‰í™œí™”ëœ í™•ë¥ ì„ ê¸°ë°˜ìœ¼ë¡œ ìƒˆë¡œìš´ ê°ì • ì˜ˆì¸¡
    # df.columns.get_loc()ë¥¼ ì‚¬ìš©í•˜ì—¬ í´ë˜ìŠ¤ IDë¥¼ ë™ì ìœ¼ë¡œ ì°¾ìŒ
    emotion_mapping_rev = {v: k for k, v in emotion_mapping.items()}
    class_labels = [emotion_mapping_rev[col.replace('probability_', '')] for col in smoothed_probs.columns]
    
    smoothed_emotion_indices = np.argmax(smoothed_probs.values, axis=1)
    df['smoothed_emotion_id'] = np.array(class_labels)[smoothed_emotion_indices]
    df['smoothed_emotion'] = df['smoothed_emotion_id'].map(emotion_mapping)
    
    print("í‰í™œí™” ì™„ë£Œ.")
    return df

def save_results(df, output_path, use_threshold=False):
    """
    ë¶„ì„ ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    
    Args:
        df (pd.DataFrame): ë¶„ì„ ê²°ê³¼ ë°ì´í„°í”„ë ˆì„
        output_path (str): ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
        use_threshold (bool): í™•ë¥  ì„ê³„ê°’ ì ìš© ì—¬ë¶€
    """
    # ê²°ê³¼ ì €ì¥
    df.to_csv(output_path, index=False, encoding='utf-8-sig')
    print(f"ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {output_path}")
    
    # ê°ì •ë³„ ë¶„í¬ ì¶œë ¥
    print("\nğŸ“Š ê°ì • ë¶„í¬:")
    emotion_counts = df['emotion'].value_counts()
    for emotion, count in emotion_counts.items():
        percentage = (count / len(df)) * 100
        print(f"  {emotion}: {count}ê°œ ({percentage:.1f}%)")
    
    # ì„ê³„ê°’ ì ìš©ì‹œ ì›ë³¸ê³¼ ë¹„êµ
    if use_threshold and 'original_emotion' in df.columns:
        print("\nğŸ”„ ì„ê³„ê°’ ì ìš© ì „í›„ ë¹„êµ:")
        original_counts = df['original_emotion'].value_counts()
        for emotion in emotion_counts.index:
            original_count = original_counts.get(emotion, 0)
            adjusted_count = emotion_counts[emotion]
            change = adjusted_count - original_count
            print(f"  {emotion}: {original_count} â†’ {adjusted_count} ({change:+d})")
    
    # í‰ê·  ì‹ ë¢°ë„ ì¶œë ¥
    avg_confidence = df['confidence'].mean()
    print(f"\nğŸ“ˆ í‰ê·  ì‹ ë¢°ë„: {avg_confidence:.3f}")

def main():
    parser = argparse.ArgumentParser(description='MP3 íŒŒì¼ì„ ì§€ì •ëœ ê°„ê²©ìœ¼ë¡œ ê°ì • ë¶„ë¥˜ (ê°œì„ ëœ ë²„ì „)')
    parser.add_argument('--input', '-i', help='ì…ë ¥ MP3 íŒŒì¼ ê²½ë¡œ (ì„ íƒì‚¬í•­, ì—†ìœ¼ë©´ ëŒ€í™”í˜• ì„ íƒ)')
    parser.add_argument('--output', '-o', help='ì¶œë ¥ CSV íŒŒì¼ ê²½ë¡œ (ì„ íƒì‚¬í•­)')
    parser.add_argument('--model_dir', '-m', default='Model', help='ëª¨ë¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ')
    parser.add_argument('--segment', '-s', type=float, default=5.0, help='ì„¸ê·¸ë¨¼íŠ¸ ê¸¸ì´ (ì´ˆ)')
    parser.add_argument('--no-threshold', action='store_true', help='í™•ë¥  ì„ê³„ê°’ ì ìš© ì•ˆí•¨')
    
    args = parser.parse_args()
    
    # ì…ë ¥ íŒŒì¼ ê²½ë¡œ
    input_file = args.input
    if not input_file:
        # ëŒ€í™”í˜•ìœ¼ë¡œ íŒŒì¼ ì„ íƒ
        input_file = get_mp3_file_interactive()
    
    # ë¶„ì„ ì„¤ì • (ìë™ ì„¤ì •: 2ì´ˆ ì„¸ê·¸ë¨¼íŠ¸, ì„ê³„ê°’ ì ìš©)
    if len(sys.argv) == 1:  # ì¸ìˆ˜ ì—†ì´ ì‹¤í–‰ëœ ê²½ìš°
        segment_duration = 2.0
        use_threshold = True
        print(f"\nâœ… ìë™ ì„¤ì • ì ìš©:")
        print(f"   ì„¸ê·¸ë¨¼íŠ¸ ê¸¸ì´: {segment_duration}ì´ˆ")
        print(f"   í™•ë¥  ì„ê³„ê°’ ì ìš©: {'ì˜ˆ' if use_threshold else 'ì•„ë‹ˆì˜¤'}")
    else:
        segment_duration = args.segment
        use_threshold = not args.no_threshold
    
    output_folder = os.path.join("TestMusic", "Result")
    os.makedirs(output_folder, exist_ok=True)
    
    # ì¶œë ¥ íŒŒì¼ ê²½ë¡œ ì„¤ì •
    if args.output:
        output_file = args.output
    else:
        # ì…ë ¥ íŒŒì¼ëª…ì—ì„œ í™•ì¥ìë¥¼ ì œê±°í•˜ê³  ì„¤ì • ì •ë³´ ì¶”ê°€
        base_name = os.path.splitext(os.path.basename(input_file))[0]
        threshold_suffix = "_threshold" if use_threshold else "_original"
        segment_suffix = f"_{int(segment_duration)}s"
        output_file = os.path.join(output_folder, 
                                 f"{base_name}_emotion_analysis{threshold_suffix}{segment_suffix}.csv")

    # ì…ë ¥ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
    if not os.path.exists(input_file):
        print(f"ì˜¤ë¥˜: ì…ë ¥ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {input_file}")
        return
    
    try:
        # í•™ìŠµëœ ëª¨ë¸ê³¼ ìŠ¤ì¼€ì¼ëŸ¬ ë¡œë“œ
        model, scaler, feature_names, emotion_mapping = load_trained_model_and_scaler(args.model_dir)
        
        # MP3 íŒŒì¼ ì²˜ë¦¬
        results_df = process_mp3_file(input_file, model, scaler, feature_names, emotion_mapping,
                                     segment_duration, use_threshold)
        
        # ì˜ˆì¸¡ ê²°ê³¼ í‰í™œí™”
        results_df = smooth_predictions(results_df, emotion_mapping, window_size=3)
        
        # ê²°ê³¼ ì €ì¥
        save_results(results_df, output_file, use_threshold)
        
        print(f"\nğŸ‰ ê°ì • ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print(f"ğŸ“ ì…ë ¥ íŒŒì¼: {input_file}")
        print(f"ğŸ“ ì¶œë ¥ íŒŒì¼: {output_file}")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {e}")
        return

if __name__ == "__main__":
    # ëª…ë ¹í–‰ ì¸ìˆ˜ê°€ ì—†ì„ ë•Œë„ ì‹¤í–‰
    import sys
    if len(sys.argv) == 1:
        print("ğŸµ === ê°œì„ ëœ MP3 ê°ì • ë¶„ì„ í”„ë¡œê·¸ë¨ === ğŸµ")
        print("ì´ í”„ë¡œê·¸ë¨ì€ MP3 íŒŒì¼ì„ ë¶„ì„í•˜ì—¬ ê°ì •ì„ ë¶„ë¥˜í•©ë‹ˆë‹¤.")
        print("ğŸ”§ ê°œì„  ì‚¬í•­:")
        print("  â€¢ 2ì´ˆ ì„¸ê·¸ë¨¼íŠ¸ë¡œ ë¹ ë¥¸ ë³€í™” ê°ì§€")
        print("  â€¢ í™•ë¥  ì„ê³„ê°’ ì ìš©ìœ¼ë¡œ Amusing ê³¼ë„ ë¶„ë¥˜ ë°©ì§€")
        print("  â€¢ ë” ìƒì„¸í•œ ë¶„ì„ ê²°ê³¼ ì œê³µ")
        print("\nğŸ“‹ ì‚¬ìš©ë²•:")
        print("1. ëŒ€í™”í˜• ì‹¤í–‰: python 3_ImprovedMP3Model.py")
        print("2. ëª…ë ¹í–‰ ì‹¤í–‰: python 3_ImprovedMP3Model.py --input file.mp3 --segment 2")
        print("\nğŸš€ ëŒ€í™”í˜• ì‹¤í–‰ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
        print("-" * 60)
        
    main() 